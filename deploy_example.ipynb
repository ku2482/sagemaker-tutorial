{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "from io import StringIO\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './source_dir'\n",
    "dataset_dir = './dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "reviews = pd.read_csv(os.path.join(dataset_dir, '10000_review.csv'))\n",
    "sentences = pd.read_csv(os.path.join(dataset_dir, '10000_sentence.csv'))\n",
    "embeddings = np.load(os.path.join(dataset_dir, '10000_embedding.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RDIJS7QYB6XNR</td>\n",
       "      <td>B00EDBY7X8</td>\n",
       "      <td>Monopoly Junior Board Game</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Excellent!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_id  product_id               product_title  star_rating  \\\n",
       "0  RDIJS7QYB6XNR  B00EDBY7X8  Monopoly Junior Board Game          5.0   \n",
       "\n",
       "  review_headline   review_body  \n",
       "0      Five Stars  Excellent!!!  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RDIJS7QYB6XNR</td>\n",
       "      <td>excellent!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_id     sentence\n",
       "0  RDIJS7QYB6XNR  excellent!!"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is uploaded to s3://sagemaker-us-west-2-010942746803/data\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset.\n",
    "sess = sagemaker.Session()\n",
    "s3_train_data = sess.upload_data(path=dataset_dir, key_prefix='data')\n",
    "print(f\"Training data is uploaded to {s3_train_data}\")\n",
    "\n",
    "data_channels = {'train': s3_train_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator.\n",
    "estimator = PyTorch(\n",
    "    entry_point='entry_point.py',\n",
    "    source_dir='source_dir',\n",
    "    dependencies=['search'],\n",
    "    role=role,\n",
    "    framework_version='1.3.1',\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-24 15:41:37 Starting - Starting the training job...\n",
      "2020-01-24 15:41:39 Starting - Launching requested ML instances......\n",
      "2020-01-24 15:42:40 Starting - Preparing the instances for training......\n",
      "2020-01-24 15:43:47 Downloading - Downloading input data...\n",
      "2020-01-24 15:44:11 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-24 15:44:49,416 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-24 15:44:49,420 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-01-24 15:44:49,435 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-24 15:44:49,436 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\n",
      "2020-01-24 15:44:48 Training - Training image download completed. Training in progress.\u001b[34m2020-01-24 15:44:57,770 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-24 15:44:57,770 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-24 15:44:57,770 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-24 15:44:57,770 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmp9zjcghtm/module_dir\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (4.36.1)\u001b[0m\n",
      "\u001b[34mCollecting Unidecode\n",
      "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-ml-py\n",
      "  Downloading nvidia-ml-py-375.53.tar.gz (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting clean-text\n",
      "  Downloading clean_text-0.1.1-py3-none-any.whl (9.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting sentence-transformers\n",
      "  Downloading sentence-transformers-0.2.5.tar.gz (49 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.21.2)\u001b[0m\n",
      "\u001b[34mCollecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.6.1-cp36-cp36m-manylinux2010_x86_64.whl (7.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting ftfy\n",
      "  Downloading ftfy-5.6.tar.gz (58 kB)\u001b[0m\n",
      "\u001b[34mCollecting transformers==2.3.0\n",
      "  Downloading transformers-2.3.0-py3-none-any.whl (447 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r requirements.txt (line 5)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r requirements.txt (line 5)) (1.16.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from sentence-transformers->-r requirements.txt (line 5)) (1.2.2)\u001b[0m\n",
      "\u001b[34mCollecting nltk\n",
      "  Downloading nltk-3.4.5.zip (1.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 6)) (0.14.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from ftfy->clean-text->-r requirements.txt (line 4)) (0.1.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from transformers==2.3.0->sentence-transformers->-r requirements.txt (line 5)) (1.11.7)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2020.1.8-cp36-cp36m-manylinux2010_x86_64.whl (689 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==2.3.0->sentence-transformers->-r requirements.txt (line 5)) (2.22.0)\u001b[0m\n",
      "\u001b[34mCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.38.tar.gz (860 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk->sentence-transformers->-r requirements.txt (line 5)) (1.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.3.0->sentence-transformers->-r requirements.txt (line 5)) (0.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.3.0->sentence-transformers->-r requirements.txt (line 5)) (0.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.15.0,>=1.14.7 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.3.0->sentence-transformers->-r requirements.txt (line 5)) (1.14.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.3.0->sentence-transformers->-r requirements.txt (line 5)) (1.25.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.3.0->sentence-transformers->-r requirements.txt (line 5)) (2019.11.28)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.3.0->sentence-transformers->-r requirements.txt (line 5)) (2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.3.0->sentence-transformers->-r requirements.txt (line 5)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.3.0->sentence-transformers->-r requirements.txt (line 5)) (7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.7->boto3->transformers==2.3.0->sentence-transformers->-r requirements.txt (line 5)) (0.15.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.7->boto3->transformers==2.3.0->sentence-transformers->-r requirements.txt (line 5)) (2.8.1)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nvidia-ml-py, sentence-transformers, default-user-module-name, ftfy, nltk, sacremoses\n",
      "  Building wheel for nvidia-ml-py (setup.py): started\n",
      "  Building wheel for nvidia-ml-py (setup.py): finished with status 'done'\n",
      "  Created wheel for nvidia-ml-py: filename=nvidia_ml_py-375.53.1-py3-none-any.whl size=22385 sha256=12ecc31977acc65c296132063fce55b9a79621192530a1bc35f0268e247f79ad\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/06/44/34ac3af4f3c0cb0f197db02efafe858509a88ccd28c3cafbe4\n",
      "  Building wheel for sentence-transformers (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.5-py3-none-any.whl size=64944 sha256=05f803439153b55e75107684c1a4de70e49661e92369ff4af270cb0e642b6ab1\n",
      "  Stored in directory: /root/.cache/pip/wheels/db/86/e5/5f4959cdb0c5beb4e89f5dd3af4525cf76c3efa0f662ad991c\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=406042177 sha256=de2219ae90af354d52a6b6ba25a4ea9731728cec5876bfd6850d3d919f39c38a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-q7jjjmz5/wheels/91/0d/64/442a7106086f90ebf0aacdd29a956a78860c506e4c09057ee5\n",
      "  Building wheel for ftfy (setup.py): started\n",
      "  Building wheel for ftfy (setup.py): finished with status 'done'\n",
      "  Created wheel for ftfy: filename=ftfy-5.6-py3-none-any.whl size=44553 sha256=3a3714b748bfca6ceb7632cb2e06fcb661e3008d8fda963b59c590b017f17687\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/e3/08/bc85bd99c87c453a4329d3a5f9af5bf1364af38ebd462353f0\n",
      "  Building wheel for nltk (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449907 sha256=2887d12c1a46f32c8ba3b13a07f0201f02416d26fc2314e97b2eb95574315ecb\n",
      "  Stored in directory: /root/.cache/pip/wheels/e3/c9/b0/ed26a73ef75a53145820825afa8e2d2c9b30fe9f6c10cd3202\n",
      "  Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-py3-none-any.whl size=884629 sha256=f555e4279919e7ff0986c4595d0e188460642bb23e1258bdb6bcd8c859b2d0ce\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/e9/be/8b52f6e7e8c333b56f9440575b4c5eb4d96d27b5d22df5a71e\u001b[0m\n",
      "\u001b[34mSuccessfully built nvidia-ml-py sentence-transformers default-user-module-name ftfy nltk sacremoses\u001b[0m\n",
      "\u001b[34mInstalling collected packages: Unidecode, nvidia-ml-py, ftfy, clean-text, regex, sentencepiece, sacremoses, transformers, nltk, sentence-transformers, faiss-cpu, default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed Unidecode-1.1.1 clean-text-0.1.1 default-user-module-name-1.0.0 faiss-cpu-1.6.1 ftfy-5.6 nltk-3.4.5 nvidia-ml-py-375.53.1 regex-2020.1.8 sacremoses-0.0.38 sentence-transformers-0.2.5 sentencepiece-0.1.85 transformers-2.3.0\u001b[0m\n",
      "\u001b[34m2020-01-24 15:45:49,604 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-01-24 15:45:49,621 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-01-24 15:45:49,637 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-01-24 15:45:49,651 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-24-15-41-09-283\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-010942746803/pytorch-training-2020-01-24-15-41-09-283/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"entry_point\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"entry_point.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=entry_point.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=entry_point\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-010942746803/pytorch-training-2020-01-24-15-41-09-283/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-24-15-41-09-283\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-010942746803/pytorch-training-2020-01-24-15-41-09-283/source/sourcedir.tar.gz\",\"module_name\":\"entry_point\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"entry_point.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python entry_point.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[nltk_data] Downloading package punkt to /root/nltk_data...\u001b[0m\n",
      "\u001b[34m[nltk_data]   Unzipping tokenizers/punkt.zip.\u001b[0m\n",
      "\u001b[34m2020-01-24 15:45:59,882 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-01-24 15:46:10 Uploading - Uploading generated training model\n",
      "2020-01-24 15:47:38 Completed - Training job completed\n",
      "Training seconds: 231\n",
      "Billable seconds: 231\n"
     ]
    }
   ],
   "source": [
    "# Train.\n",
    "estimator.fit(data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "# Deploy the trained model.\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "\n",
    "predictor.content_type = 'application/json'\n",
    "predictor.serializer = json_serializer\n",
    "predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\n",
    "    'query': 'it still looks brand new too'\n",
    "}\n",
    "response = predictor.predict(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "- review_id\n",
      "R1V5I8W64XQA8R\n",
      "- product_id\n",
      "B00388C3C4\n",
      "- product_title\n",
      "Fisher-Price Laugh & Learn Learning Kitchen Activity Center\n",
      "- star_rating\n",
      "5.0\n",
      "- review_headline\n",
      "One of our most beloved toys, even 1.5 yrs later\n",
      "- review_body\n",
      "My son received this as a gift when he was 9 months old. He played with it daily (sometimes 30 min at a time) until he was almost 2, when he graduated to a big kitchen. This was put away for a few months, but recently came out again now that his little sister is 6 months old. It's one of the few things that they can really play with together, one on each side.  My son (now 2.5) loves playing with it with his sis (and she of course loves it too). We have a lot of toys, but this one stands apart as versatile, fun, and extremely long lived! It still looks brand new too.\n",
      "- product_search_score\n",
      "0.9975305795669556\n",
      "----------\n",
      "- review_id\n",
      "R2UIBI7R96HXAP\n",
      "- product_id\n",
      "B0007IG43W\n",
      "- product_title\n",
      "Monsties Thly HP\n",
      "- star_rating\n",
      "5.0\n",
      "- review_headline\n",
      "For those saying not good quality, I have had this puppet for 8 ...\n",
      "- review_body\n",
      "For those saying not good quality, I have had this puppet for 8 years, through 2 kids and many washings. It still looks brand new.\n",
      "- product_search_score\n",
      "0.97686767578125\n",
      "----------\n",
      "- review_id\n",
      "R2I6KGQGLGTLSI\n",
      "- product_id\n",
      "B00JV52PQ2\n",
      "- product_title\n",
      "Fun Express Superhero Sticker Roll\n",
      "- star_rating\n",
      "5.0\n",
      "- review_headline\n",
      "Five Stars\n",
      "- review_body\n",
      "came as described - brand new, thanks\n",
      "- product_search_score\n",
      "0.8723194599151611\n",
      "----------\n",
      "- review_id\n",
      "R1LIZTMDTFHQWJ\n",
      "- product_id\n",
      "B00XTRG5UA\n",
      "- product_title\n",
      "Super Mario Sitting Princess Peach Plush Toy Doll Kids Gift 20 Cm by handstiched\n",
      "- star_rating\n",
      "5.0\n",
      "- review_headline\n",
      "Very happy!\n",
      "- review_body\n",
      "It was exactly what I expected! Received it and its in mint condition and is brand new! Very happy!\n",
      "- product_search_score\n",
      "0.8646432161331177\n",
      "----------\n",
      "- review_id\n",
      "R3TNJJXAH0I5Z\n",
      "- product_id\n",
      "B0010K356K\n",
      "- product_title\n",
      "Hess 1998 Truck Recreation Van with Dune Buggy and Motorcycle\n",
      "- star_rating\n",
      "5.0\n",
      "- review_headline\n",
      "Perfect!\n",
      "- review_body\n",
      "We received this for a gift and it was in perfect brand new condition.  We had to remove all the battery pull tabs on the little car. No discoloring on the truck, and box was in good shape!\n",
      "- product_search_score\n",
      "0.8149399757385254\n"
     ]
    }
   ],
   "source": [
    "for value in response.values():\n",
    "    print('-' * 10)\n",
    "    for k, v in value.items():\n",
    "        print(f'- {k}')\n",
    "        print(f'{v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
